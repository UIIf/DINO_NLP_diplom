\documentclass[../part_3.tex]{subfiles}
\usepackage{multirow}
\begin{document}
\subsection{Сравнение моделей}
\par Сравнение было решено провести с моделями CodeBert\cite{feng2020codebertpretrainedmodelprogramming} и UnixCoder\cite{guo2022unixcoder}, так как они считаются лучшими на данный момент.
\begin{figure}[H]
    \centering
    \includegraphics[width=.5\linewidth]{tokenized_data.png}
    \caption{Код, разделенный токенизатором}
    \label{fig:tokenized}
\end{figure}
\par На рисунке \ref{fig:tokenized} изображен текст, разбитый на токены, где токены отличаются цветом.
\par Изначально весь выбраный датасет был пропущен через модели DinoNLP, CodeBert и UnixCoder, а полученные вектора сохранены в numpy файлы.
\par Так как для сравнения будет решаться задача классификации в качестве базового решения (baseline) был выбран наивный баесовский классификатор(Naive Bayes Classifier). Наивный байесовский классификатор был выбран поскольку он является классическим методом машинного обучения, широко применяемым для задач обработки текстовых данных. Во время предобработки, исходный текст был токензирован и в дальнейшем токены были трансформированны с помощью TF-IDF.
\subsubsection{Классификация номера задания}
\par Было выбрано 48 заданий из набора данных от IBM в которых больше всего принятых решений. Размер тренировочного набора - 65059. Размер тестового набора - 16265. После этого было решено использовать KNN классификатор и MLP классификатор предсказания номера задачи.
\par Для KNN был выставлен параметр - 10 ближайших соседей.
\par MLP имело 11 слоев, с функциями активации ReLU.
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c||c|c|c|c|}\hline 
        &BaseLine&&DinoNLP&CodeBert&UnixCoder\\ \hline 
        \multirow{2}{*}{Acc,\%}&\multirow{2}{*}{76}&KNN&80&80&89\\\cline{3-6}
        &&MLP&85&81&95\\\hline
    \end{tabular}  
    \caption{Точность в процентах решения задачи определения номера задания}
\end{table}
\par Решение при помощи модели DinoNLP значительно выше чем baseline, не уступает решению модели использующей представления модели CodeBert но в тоже время хуже, чем значительно более сложная модель UnixCoder.
\subsubsection{Классификация статуса задачи}
\par Из прошлого набора данных было выбрано одно задание в котором было больше всего примеров. В качестве целевой переменной было выбрано булевое значение, которое отображает является ли задача принятой. 
\par Размер тренировочного набора - 7838, из них 44\% приняты. Размер тестового набора - 1960, из них 44\% приняты. 
\begin{table}[H]
    \centering
    \begin{tabular}{|c|c||c|c|c|c|}\hline 
        &BaseLine&&DinoNLP&CodeBert&UnixCoder\\ \hline 
        \multirow{2}{*}{Acc,\%}&\multirow{2}{*}{72}&KNN&72&72&73\\\cline{3-6}
        &&MLP&77&79&85\\\hline
    \end{tabular}    
    \caption{Точность в процентах решения задачи определения статуса решения}
\end{table}
\par Решение при помощи модели DinoNLP значительно выше чем baseline, в некоторых случаях уступает решению модели использующей представления модели CodeBert но в тоже время хуже, чем значительно более сложная модель UnixCoder. % #TODO Задача списывания
\subsubsection{Визуализация токенных представлений через цветовое пространство}
\par Метод визуализации токенных представлений через цветовое представление позволяет интерпретировать семантические свойства текста через цветовую проекцию векторных представлений. Модель выдает похожие цвета семантически схожим токенам. Каждая из моделей обработала по 48 прмиеров решений, полученные представления для каждого из токенов в дальнейшем с помощью процесса снижения размерности t-SNE\cite{tsne} представления были ужаты до 3х мерных. Полученные вектора были нормализованны и использованны как цвет, для отображения токенов.

\begin{figure}[H]
    \centering
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{multicolor_texdino_48.png}
        \caption{DINO}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{multicolor_texcodebert_48.png}
        \caption{CodeBERT}
    \end{subfigure}
    \hfill
    \begin{subfigure}{.32\textwidth}
        \centering
        \includegraphics[width=.9\linewidth]{multicolor_texunixcoder_48.png}  
        \caption{UnixCoder}
    \end{subfigure}
    \vspace{1cm}
\end{figure}
\par На основании представленных изображений можно сделать вывод, что модель Dino выделяет ключевые слова (такие как int, for, printf), при этом каждому ключевому слову назначается цвет, который не является заранее фиксированным (например, цвет может варьироваться в зависимости от того, определяет ли int локальную или глобальную переменную). Кроме того, в отличие от моделей CodeBert и UnixCoder, модель Dino присваивает различным переменным и константам разные цвета, что является важным отличием.
\end{document}