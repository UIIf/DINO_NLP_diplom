\documentclass[../part_1.tex]{subfiles}

\begin{document}
\subsection{Обработка естественного языка}
\par Обработка естественного языка -- направления искусственного интеллекта, объединяющее лингвистику и компьютерные науки для анализа, понимания и генерации человечесского языка. Современные \acrshort{nlp}-системы способны обрабатывать текст не только на урвне слов, но и понимать конеткст, иронию и даже культурные отсылки.
\par В задачах обработки естественного языка входные данные по своей природе не имеют жестких ограничений по длинне и структуре. По этому для эффективной обработки таких данных требуются архитектуры способные учитывать произвольные зависимости между элементами последовательности. 
\par Чтобы представить последовательность текста в виде числе используют токенизаторы. Токенизатор -- инструмент который разбивает текст на отдельные элементы. Элементы могут быть как словами так и отдельными символами. Этот процесс помогает стандартизировать данные и сокращает объем данных. В современных токенизаторах токен может описывать самые часто встречающиеся слова, отдельные части слов(корни, суффексы, окончания) так и отдельные символы. 
\par Для того чтобы легче менять значимость токена, используется слой Embedding. Он принимает на вход максимальное количество токенов, и размерность векторов представления. Далее создается матрица в которой каждому токену присваеватся своя строка. В процессе работы модели пооследовательность токенов преобразуется в последовательность из строк.
\par Для обучения векторов embedding делают предобучение модели. Предобучение -- процесс первоначальног обучения нейросети на большом объеме неразмеченных данных с использованием методов \acrfull{ssl}. На этом этапе модель так же учится понимать синтаксис, семантику и контекст слов, что позволяет ей в дальнейшем эффективно адаптироваться к узким задачам. Основными методами предобучения являются \acrshort{mlm}\cite{sinha2021maskedlanguagemodelingdistributional} и \acrshort{rtd}.
\par После предобучения модель дообучают на меньших размеченных датасетах под конкретную задачу. Например дообученная сеть может быть использованн для классификации спама или генерации ответов в чат боте. Такой подходи экономит время и улучшает качество модели, поскольку предобучение закладывает в модели базовое понимание языка. Таким образом даже маленький набор целевых данных может демонстрировать высокую точность.

\end{document}