\documentclass[../part_1.tex]{subfiles}

\begin{document}
\subsubsection{Обучение с подкреплением} % Обучение с уподкреплением
    \label{sec:reinforcement_learning}
    %  TODO переписать предложение
    \par Обучение с подкреплением --  это вид машинного обучения, при котором агент(модель) обучается на основе опыта взаимодействия со средой, принимая решения которые максимизируют награду.
    \par В отличие от прошлых методов, агенты ориентированы на последовательное принятие решений в условиях неопредленности.
    \par Основное преимущество обучения с подкреплением:
    \begin{itemize}
        \item \textit{Подходит для задач с отложенной наградой} -- Может учитывать долгосрочные последствия действий, а не только мгновенную выгоду.
        \item \textit{Возможность обучения без размеченных данных} -- Не требует готовых "правильных ответов".
    \end{itemize}
    \par Основные недостатки обучения с подкреплением:
    \begin{itemize}
        \item \textit{Высокие вычислительные затраты} -- Требует миллионов (иногда миллиардов) попыток для обучения.
        \item \textit{Проблема исследования-эксплуатации} -- Агент должен балансировать между исследованием и эксплуатацией. Исследование -- проба новых действий, для поиска лучшей стратегии. Эксплуатация -- использование уже известных лучших действий.
    \end{itemize}
    \par Пример моделей которые обучаются с помощью обучения с учителем:
    \begin{itemize}
        \item К средних
        \item Генеративные состязательные сети
    \end{itemize}
\end{document}